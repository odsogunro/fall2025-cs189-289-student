{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT: On Colab, we expect your homework to be in the cs189 folder\n",
    "## Please contact staff if you encounter any problems with installing dependencies\n",
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd /content/drive/MyDrive/cs189/hw/hw1\n",
    "    %pip install -r ./requirements.txt\n",
    "    !pip install -U kaleido plotly\n",
    "    import kaleido\n",
    "    kaleido.get_chrome_sync()\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = pio.renderers.default + \"+png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"fashion_pt_2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"berkeley.css\">\n",
    "\n",
    "<h1 class=\"cal cal-h1\">Homework 1.2 – AGI, Everywhere, All at Once</h1>\n",
    "\n",
    "Welcome to Homework 1.2! In this assignment, you will build on the foundational skills you developed in part 1. You will gain hands-on experience with building and evaluating machine learning models, debugging performance issues, and exploring strategies to improve model accuracy. By the end of this assignment, you will have a deeper understanding of how to work with classifiers and analyze their performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Due Date: Friday, September 26, 11:59 PM\n",
    "\n",
    "This assignment is due on **Friday, September 26, at 11:59 PM**. You must submit your work to Gradescope by this deadline. Please refer to the syllabus for the [Slip Day policy](https://eecs189.org/fa25/syllabus/#slip-days). No late submissions will be accepted beyond the details outlined in the Slip Day policy.\n",
    "\n",
    "### Submission Tips:\n",
    "- **Plan ahead**: We strongly encourage you to submit your work several hours before the deadline. This will give you ample time to address any submission issues.\n",
    "- **Reach out for help early**: If you encounter difficulties, contact course staff well before the deadline. While we are happy to assist with submission issues, we cannot guarantee responses to last-minute requests.\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "This notebook contains a series of tasks designed to help you practice and apply key concepts in machine learning. You will complete all the TODOs in the notebook, which include both coding and written response questions. Some tasks are open-ended, which allows you to explore and experiment with different approaches.\n",
    "\n",
    "### Key Learning Objectives:\n",
    "1. Build and evaluate machine learning classifiers.\n",
    "2. Debug and analyze model performance.\n",
    "3. Explore techniques to improve accuracy.\n",
    "4. Gain experience with tools like `numpy`, `pandas`, `plotly`, and `scikit-learn`.\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "### Grading Breakdown\n",
    "\n",
    "| Question | Manual Grading? | Points |\n",
    "|----------|-----------------|--------|\n",
    "| 5a       | No              | 2      |\n",
    "| 5b       | No              | 4      |\n",
    "| 5c       | No              | 1      |\n",
    "| 5d       | Yes             | 2      |\n",
    "| 6a       | No              | 3      |\n",
    "| 6b       | Yes             | 2      |\n",
    "| 6c       | No              | 1      |\n",
    "| 6d       | Yes             | 1      |\n",
    "| 7a       | No              | 3      |\n",
    "| 7b       | Yes             | 3      |\n",
    "| 8a       | Yes             | 3      |\n",
    "| 8b       | No              | 3      |\n",
    "| 8c       | No              | 5      |\n",
    "| 8d       | Yes             | 1      |\n",
    "| 9a       | No              | 5      |\n",
    "| **Total**|                 | **39** |\n",
    "\n",
    "</div>\n",
    "\n",
    "**Note**: \"Manual\" questions are written response questions that will be graded manually by the course staff. All other questions will be graded automatically by the autograder.\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions:\n",
    "1. Carefully read each question and its requirements.\n",
    "2. Complete all TODOs in the notebook. You may add extra lines of code if needed to implement your solution.\n",
    "3. For manual questions, provide clear and concise written responses.\n",
    "4. Test your code thoroughly to ensure it meets the requirements.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torchvision\n",
    "import os\n",
    "from scipy.ndimage import rotate\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # For saving/loading the model\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMPORTANT:** \n",
    "- Do not change the random seed values!!!\n",
    "- Before you submit your notebook, remember to set `save_models=True` and `load_models=True`. This saves your final models which we will use for the autograder. Set these to false if you are still tweaking your model setup. We have provided code for saving models - **do not change these file names!!**\n",
    "- When uploading your notebook, make sure to include your model file `classifier.joblib` in your submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducible results\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# IMPORTANT: set save_models to True to save trained models. YOU NEED TO DO THIS FOR THE AUTOGRADER TO WORK.\n",
    "save_models = True\n",
    "load_saved_models = False # After training, you can set this to True to load the saved models and not have to re-train them.\n",
    "IS_GRADING_ENV = os.getenv(\"IS_GRADING_ENV\") == \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helper function to show images\n",
    "def show_images(images, max_images=40, ncols=5, labels = None, reshape=False):\n",
    "    \"\"\"Visualize a subset of images from the dataset.\n",
    "    Args:\n",
    "        images (np.ndarray or list): Array of images to visualize [img,row,col].\n",
    "        max_images (int): Maximum number of images to display.\n",
    "        ncols (int): Number of columns in the grid.\n",
    "        labels (np.ndarray, optional): Labels for the images, used for facet titles.\n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: A Plotly figure object containing the images.\n",
    "    \"\"\"\n",
    "    if isinstance(images, list):\n",
    "        images = np.stack(images)\n",
    "    n = min(images.shape[0], max_images) # number of images to show\n",
    "    px_height = 220 # height of each image in pixels\n",
    "    if reshape:\n",
    "        images = images.reshape(images.shape[0], 28, 28)\n",
    "    fig = px.imshow(images[:n, :, :], color_continuous_scale='gray_r', \n",
    "                    facet_col = 0, facet_col_wrap=ncols,\n",
    "                    height = px_height * int(np.ceil(n/ncols)))\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.update_xaxes(showticklabels=False, showgrid=False)\n",
    "    fig.update_yaxes(showticklabels=False, showgrid=False)\n",
    "    if labels is not None:\n",
    "        # Extract the facet number and replace with the label.\n",
    "        fig.for_each_annotation(lambda a: a.update(text=labels[int(a.text.split(\"=\")[-1])]))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Fashion-MNIST Dataset  \n",
    "\n",
    "Let's reload the Fashion-MNIST dataset. As a reminder, this dataset contains 70k images (60k training, 10k testing) of 28x28 grayscale images of clothing divided into the following 10 classes:\n",
    "1. **T-shirt/top**\n",
    "2. **Trouser**\n",
    "3. **Pullover**\n",
    "4. **Dress**\n",
    "5. **Coat**\n",
    "6. **Sandal**\n",
    "7. **Shirt**\n",
    "8. **Sneaker**\n",
    "9. **Bag**\n",
    "10. **Ankle boot**\n",
    "\n",
    "### Dataset Structure:\n",
    "- **Images**: Each image is represented as a 28x28 grayscale matrix, where each value corresponds to the pixel intensity.\n",
    "- **Targets**: Each image is associated with a label (0-9), which maps to one of the 10 classes listed above.\n",
    "\n",
    "### Data Preparation:\n",
    "In the code cell below, we:\n",
    "1. Load the Fashion-MNIST training dataset using `torchvision.datasets.FashionMNIST`.\n",
    "2. Extract the images and targets into `NumPy` arrays for easier manipulation.\n",
    "3. Create a `pandas DataFrame` (`df`) to store the images and their corresponding labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FashionMNIST training dataset\n",
    "train_data = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "images = train_data.data.numpy().astype(float)  # Convert images to numpy array\n",
    "targets = train_data.targets.numpy()  # Extract labels\n",
    "class_dict = {i:class_name for i,class_name in enumerate(train_data.classes)}\n",
    "labels = np.array([class_dict[t] for t in targets])  # Map labels to class names\n",
    "n = len(images)  # Total samples\n",
    "class_names = list(class_dict.values())\n",
    "print(f\"Loaded FashionMNIST with {n} samples. Classes: {class_dict}\")\n",
    "print(\"Classes: {}\".format(class_dict))\n",
    "print(\"Image shape: {}\".format(images[0].shape))\n",
    "print(\"Image dtype: {}\".format(images[0].dtype))\n",
    "\n",
    "\n",
    "# Creating a DataFrame with the images and labels\n",
    "df = pd.DataFrame({\"image\": images.tolist(), \"label\": labels})\n",
    "# Cast image as numpy array\n",
    "df['image'] = df['image'].apply(lambda x: np.array(x).reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Training) Fitting a Classifier\n",
    "\n",
    "Just like in part 1, let's train a 2-layer MLP classifier on the original data and see how it performs.\n",
    "\n",
    "**Task:** Copy and paste your code from part 1 (problem 3c). \n",
    "\n",
    "Below is the reminder about the process for training any model that will follow in the next question:\n",
    "\n",
    "### Steps:\n",
    "1. **Split the Data**: Use [scikit-learn `train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to divide the dataset into training and testing subsets.\n",
    "2. **Standardize the Features**: Use [scikit-learn `StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to scale the pixel values of the images.\n",
    "3. **Train the Classifier**: Use [scikit-learn `MLPClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) to train a neural network on the training data.\n",
    "4. **Evaluate the Model**: Measure the model's accuracy on both the training and testing datasets.\n",
    "\n",
    "**Why Train-Test Split?**\n",
    "We split the dataset into training and testing subsets to evaluate the model's performance on unseen data. This helps us evaluate the model's generalization capability.\n",
    "\n",
    "**Why Standardize the Data?**\n",
    "Standardization scales the input features to have zero mean and unit variance. This helps the MLP converge faster during training and improves the stability of the optimization process.\n",
    "\n",
    "Useful docs:\n",
    "* [scikit-learn train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "* [scikit-learn MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "* [scikit-learn Standard Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Extract image data and labels for training and testing\n",
    "X_train = np.stack(train_df['image'].to_numpy())  # Training images\n",
    "X_test = np.stack(test_df['image'].to_numpy())    # Testing images\n",
    "y_train = train_df['label'].to_numpy()            # Training labels\n",
    "y_test = test_df['label'].to_numpy()              # Testing labels\n",
    "\n",
    "# Print the shapes of the training and testing datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # for saving the model\n",
    "\n",
    "if (load_saved_models or IS_GRADING_ENV) and os.path.exists('mlp_fashionmnist_model.joblib'):\n",
    "    model = joblib.load(\"mlp_fashionmnist_model.joblib\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "else:\n",
    "    # TODO: paste your training code from part 1 (problem 3c) here setting random_state=SEED\n",
    "    ...\n",
    "if save_models:\n",
    "    # Save the trained model and scaler to disk\n",
    "    joblib.dump(model, \"mlp_fashionmnist_model.joblib\")\n",
    "    print(\"Model and scaler saved to disk.\")\n",
    "\n",
    "train_df['predicted_label'] = model.predict(X_train_sc)\n",
    "test_df['predicted_label'] = model.predict(X_test_sc)\n",
    "\n",
    "train_df['correct'] = train_df['predicted_label'] == train_df['label']\n",
    "test_df['correct'] = test_df['predicted_label'] == test_df['label']\n",
    "\n",
    "print(f\"Training accuracy: {train_df['correct'].mean():.3f}\")\n",
    "print(f\"Test accuracy: {test_df['correct'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Regression Analysis\n",
    "\n",
    "In this section, we will switch from classification to regression. The goal is to predict the price of clothing items based on their image features. Follow the steps below to load the price data, train a regression model, and evaluate its performance.\n",
    "\n",
    "### Problem 5a: Training a Linear Regression Model\n",
    "\n",
    "**Task**: Use `pandas` and `scikit-learn` to train a linear regression model to predict prices:\n",
    "\n",
    "1. **Join the DataFrames**: \n",
    "    - Combine the price data with the original `train_df` and `test_df` using the [`join`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) method.\n",
    "    - Store the resulting training data in `prices_train` and the testing data in `prices_test`.\n",
    "\n",
    "    **Hint**: Think about which column can serve as the key for joining the `prices` DataFrame with the original `train_df` and `test_df`.\n",
    "\n",
    "2. **Train the Model**:\n",
    "    - Use `LinearRegression` from [`sklearn.linear_model`](https://scikit-learn.org/stable/modules/linear_model.html) to train a regression model.\n",
    "    - Ensure that the model predicts only positive prices.\n",
    "\n",
    "3. **Store Predictions**:\n",
    "    - Add the predicted prices to the `prices_test` `DataFrame`.\n",
    "\n",
    "**Important for grading**: Name your model `price_model`.\n",
    "\n",
    "**Expected Output**:\n",
    "The `prices_train` and `prices_test` `DataFrames` should look like this:\n",
    "\n",
    "| key_0 |      image      |    label    | predicted_label | correct | Price |\n",
    "|-------|-----------------|-------------|-----------------|---------|-------|\n",
    "| 48572 | [0.0, 0.0, ...] |   Sneaker   |     Sneaker     |   True  | 49.86 |\n",
    "| 38696 | [0.0, 0.0, ...] |    Dress    |      Dress      |   True  | 14.56 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"./data/FashionMNIST_prices.csv\")\n",
    "# TODO: Join the original `train_df` and `test_df` with the `prices` DataFrame\n",
    "prices_train = ...\n",
    "prices_test = ...\n",
    "prices_train['Price'].hist().show()\n",
    "prices_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Fit a linear regression model (price_model) on the training data with prices as the target variable\n",
    "if (load_saved_models or IS_GRADING_ENV) and os.path.exists('price_model.joblib'):\n",
    "    price_model = joblib.load('price_model.joblib')\n",
    "    print(\"Model loaded from price_model.joblib\")\n",
    "else:\n",
    "    ...\n",
    "\n",
    "# TODO: Predict the prices of the test data and add them to the test_df\n",
    "prices_test['price_prediction'] = ...\n",
    "\n",
    "if save_models:\n",
    "    joblib.dump(price_model, 'price_model.joblib')\n",
    "    print(\"Model saved to price_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5b: Evaluate Linear Regression Performance\n",
    "\n",
    "**Task**: Use `NumPy` operations to evaluate the performance of the linear regression model:\n",
    "\n",
    "1. Calculate the **Root Mean Squared Error (RMSE)** to measure the average magnitude of prediction errors.\n",
    "\n",
    "2. Calculate the **Mean Absolute Error (MAE)** to measure the average absolute difference between predicted and actual values.\n",
    "\n",
    "3. Calculate the **R-squared score (R²)** to assess how well the model explains the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_rmse(y_true, y_pred):\n",
    "  ...\n",
    "\n",
    "\n",
    "def compute_mae(y_true, y_pred):\n",
    "  ...\n",
    "\n",
    "\n",
    "def compute_r2(y_true, y_pred):\n",
    "  \"\"\"Compute R-squared score\"\"\"\n",
    "  ...\n",
    "\n",
    "def print_metrics(y_true, y_pred, dataset=\"\"):\n",
    "  \"\"\"Print all regression metrics for a dataset\"\"\"\n",
    "  rmse = compute_rmse(y_true, y_pred)\n",
    "  mae = compute_mae(y_true, y_pred)\n",
    "  r2 = compute_r2(y_true, y_pred)\n",
    "\n",
    "  print(f\"=== {dataset} Metrics ===\")\n",
    "  print(f\"RMSE: {rmse:.2f}\")\n",
    "  print(f\"MAE: {mae:.2f}\")\n",
    "  print(f\"R²: {r2:.3f}\")\n",
    "  return rmse, mae, r2\n",
    "\n",
    "# Calculate predictions\n",
    "y_train_pred = price_model.predict(X_train_sc)\n",
    "y_test_pred = price_model.predict(X_test_sc)\n",
    "\n",
    "# Compute and print metrics\n",
    "train_rmse, train_mae, train_r2 = print_metrics(prices_train['Price'], y_train_pred, \"Training\")\n",
    "test_rmse, test_mae, test_r2 = print_metrics(prices_test['Price'], y_test_pred, \"Test\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "fig = px.scatter(\n",
    "    x=prices_test['Price'],\n",
    "    y=y_test_pred,\n",
    "    title='Predicted vs Actual Prices',\n",
    "    labels={'x': 'Actual Price', 'y': 'Predicted Price'}\n",
    ")\n",
    "fig.add_trace(px.line(x=[prices_test['Price'].min(), prices_test['Price'].max()], \n",
    "                      y=[prices_test['Price'].min(), prices_test['Price'].max()]).data[0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5c: MAE, MSE, and R-Squared\n",
    "\n",
    "**Question:** What are the advantages of using MAE over MSE to measure a model's performance? What are the advantages of using MSE over MAE to measure a model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question**: What does R-squared measure? Why is it significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Problem 5d: Relationship Between Classification and Regression Errors\n",
    "\n",
    "**Task**: Analyze the relationship between classification and regression errors:\n",
    "1. For each test sample, calculate the price prediction error and the relative price prediction error:\n",
    "   - Add the following columns to `prices_test`:\n",
    "     - `price_error`: The absolute difference between the predicted price and the actual price.\n",
    "     - `price_error_relative`: The relative error, calculated as the absolute error divided by the actual price.\n",
    "2. Compute and print:\n",
    "   - `misclassified_price_error`: The average relative price error for misclassified images.\n",
    "   - `correctly_classified_price_error`: The average relative price error for correctly classified images.\n",
    "\n",
    "**Hints**:\n",
    "- Use `np.abs` to calculate the absolute value of the price error.\n",
    "- Divide the price error by the actual price to compute the relative price error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Compare how accurate the model is at classifying the images vs how accurate it is at predicting the price of the images\n",
    "# TODO: Calculate the average relative price error for correctly classified vs. misclassified images\n",
    "misclassified_price_error = ...\n",
    "correctly_classified_price_error = ...\n",
    "\n",
    "\n",
    "print(f\"\\nPrice prediction performance:\")\n",
    "print(f\"Misclassified images - Avg relative price error: {misclassified_price_error:.3f}\")\n",
    "print(f\"Correctly classified images - Avg relative price error: {correctly_classified_price_error:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 5e: Relationship Between Classification and Price Prediction Errors\n",
    "\n",
    "**Question** \n",
    "1. Is there a relationship between classification errors and price prediction errors? If so, what is the nature of this relationship?\n",
    "\n",
    "2. Why might classification errors correlate with price prediction errors? Provide possible explanations.\n",
    "\n",
    "3. Why might classification errors and price prediction errors be unrelated? Discuss potential reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Problem 6: Working with a New Test Set\n",
    "In this section, we will load a **super secret** test set. Your goal is to maximize the model's accuracy on this dataset.\n",
    "\n",
    "### Problem 6a: Inference Using `model`\n",
    "\n",
    "**Task:** Use your `model` (the MLP classifier model trained earlier in this notebook) to predict the labels of the secret test set.\n",
    "\n",
    "1. Create a `DataFrame` named `test_secret_df` to store the secret test set data.\n",
    "\n",
    "2. Use the `model` to predict the image labels for the secret test set.\n",
    "\n",
    "**Note**: Remember to use `scaler.transform` to preprocess the secret test set before making predictions. This ensures the data is scaled consistently with the training data. Learn more about `scaler.transform` [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_secret = np.load(\"./data/secret_test_set/X_test.npy\")\n",
    "y_test_secret = np.load(\"./data/secret_test_set/y_test.npy\")\n",
    "\n",
    "X_test_secret_sc = scaler.transform(X_test_secret)\n",
    "\n",
    "print(X_test_secret.shape)\n",
    "print(y_test_secret.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create a dataframe with the secret test set and use the model to predict the labels\n",
    "test_secret_df = ...\n",
    "\n",
    "...\n",
    "\n",
    "# TODO: Use the model to predict the labels and calculate the accuracy\n",
    "\n",
    "...\n",
    "\n",
    "print(f\"Test accuracy: {test_df['correct'].mean():.3f}\")\n",
    "print(f\"Secret Test accuracy: {test_secret_df['correct'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6b: Class-wise Accuracy Comparison\n",
    "\n",
    "The test accuracy is significantly lower than the training accuracy. To investigate this, let's examine the class-wise accuracies.\n",
    "\n",
    "**Task**:\n",
    "1. Plot the class-wise accuracy for both the original test set and the secret test set as a bar plot, using different hues to distinguish between the two datasets.\n",
    "\n",
    "**Hint:** You can use [Pandas's plotting functionality](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) to create the bar plot.\n",
    "\n",
    "**Expected Output**: A bar plot with two bars for each class—one representing the model's accuracy on the original test set and the other representing the accuracy on the secret test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Make a two-colored bar plot of the model's accuracy on the test set and the secret test set\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Problem 6c: Confusion Matrix\n",
    "\n",
    "To better understand why the model's accuracy is low on the super secret test set, let's analyze the confusion matrix.\n",
    "\n",
    "**Task**:\n",
    "1. Generate a confusion matrix comparing the true labels (`y_test_secret`) with the model's predictions on the secret test set.\n",
    "\n",
    "**Hint**: Use [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) from `scikit-learn`.\n",
    "\n",
    "**Expected Output**: A 10 x 10 confusion matrix with the FASHION class labels on both axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: plot a confusion matrix for the secret test set\n",
    "conf_matrix = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "### Problem 6d: Analysis of Class Accuracies and Confusion Matrix\n",
    "We observe that the types of classes being misclassified differ significantly from the original test set.\n",
    "\n",
    "**Question:** What unusual patterns do you notice in the class accuracies and confusion matrix? What might these patterns suggest about the characteristics of the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Understanding the Issue\n",
    "\n",
    "To better understand the model's performance, let's examine some misclassifications. These are instances where the model's predictions differ from the true labels.\n",
    "\n",
    "In the next cell, we will:\n",
    "1. Identify misclassified examples from the test dataset.\n",
    "2. Display these examples along with their predicted and true labels.\n",
    "\n",
    "Pay close attention to whether the misclassifications are concentrated in specific classes or if they seem random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the secret test set\n",
    "predictions_secret = model.predict(X_test_secret_sc)\n",
    "\n",
    "# Identify misclassified examples\n",
    "incorrect_secret = predictions_secret != y_test_secret\n",
    "\n",
    "# Generate labels for misclassified examples with true and predicted labels\n",
    "labels = [f\"True: {true_label}<br>Pred: {pred_label}\"\n",
    "          for true_label, pred_label in zip(y_test_secret[incorrect_secret], predictions_secret[incorrect_secret])]\n",
    "\n",
    "# Display misclassified images with their true and predicted labels\n",
    "show_images(X_test_secret[incorrect_secret], max_images=5, ncols=5, labels=labels, reshape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! It seems that all the test images are rotated. This misalignment between the training and test distributions is likely causing the model's poor performance on the rotated test set.\n",
    "\n",
    "To address this issue, we can explore two potential solutions:\n",
    "1. **Train a rotation-invariant classifier**: Modify the training data to include rotated images, which allows the model to learn features that are robust to rotation.\n",
    "2. **Undo the rotation**: Preprocess the test images to align them with the training distribution to enable the current classifier to perform better.\n",
    "3. **Use test time augmentation**: At the inference time, add augmentation to the data so the model considers augmented data at the test time. \n",
    "\n",
    "Let's investigate these approaches to improve the model's performance on the rotated test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7: Solution 1 -- Train a Rotation-Invariant Classifier\n",
    "\n",
    "First, let's try altering our training data to better align with the test distribution. This involves generating augmented data by applying random rotations to the training images. By doing so, we aim to train a model that is more robust to variations in orientation, which is a key characteristic of the rotated test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_by_angle(image, angle):\n",
    "    \"\"\"\n",
    "    Rotate an image by a specific angle.\n",
    "    \"\"\"\n",
    "    image = image.reshape(28, 28)  # Reshape the image to 28x28\n",
    "    rotated = rotate(image, angle, reshape=False, cval=0, order=1)  # Rotate the image\n",
    "    return rotated.flatten()  # Flatten the rotated image back to 1D\n",
    "\n",
    "# Visualize a rotated image\n",
    "plt.imshow(rotate_image_by_angle(X_train[0], 45).reshape(28, 28), cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7a: Generating Rotated Training Data\n",
    "\n",
    "**Task:**\n",
    "Use the provided rotation function to create augmented training data by randomly rotating the original images.\n",
    "\n",
    "**Hints:**\n",
    "- Use `NumPy`'s [random.uniform()](https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html) to generate random rotation angles.\n",
    "- Ensure the function returns two `NumPy` arrays, as `MLPClassifier` expects `NumPy` arrays as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def randomly_rotate_images(images, num_rotations_per_image=5):\n",
    "  \"\"\"\n",
    "  Create training data by rotating original images and storing the rotation angles as labels.\n",
    "  Params:\n",
    "    - images: numpy array of shape (n_images, 784)\n",
    "    - num_rotations_per_image: int, number of rotations to perform per image\n",
    "  Returns:\n",
    "    - X_augmented: numpy array of shape (n_images * num_rotations_per_image, 784)\n",
    "    - y_rotations: numpy array of shape (n_images * num_rotations_per_image,)\n",
    "  \"\"\"\n",
    "  # TODO: Implement this function\n",
    "  ...\n",
    "  raise NotImplementedError(\"Not implemented\")\n",
    "  \n",
    "num_rotations_per_image = 4\n",
    "X_train_rotated, y_train_rotations = randomly_rotate_images(X_train, num_rotations_per_image)\n",
    "y_train_augmented = np.array([y for label in y_train for y in [label]*num_rotations_per_image])\n",
    "print(X_train_rotated.shape)\n",
    "print(y_train_augmented.shape)\n",
    "\n",
    "show_images(X_train_rotated, max_images=5, ncols=5, labels=y_train_augmented, reshape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7b: Training a Rotation-Invariant Classifier\n",
    "\n",
    "Now that we have augmented our training data with rotated images, let's train a new `MLPClassifier` on this dataset.\n",
    "\n",
    "**Task**:\n",
    "Train a new `MLPClassifier` using the rotated training images `X_train_rotated_sc` and the corresponding labels `y_train_augmented`.\n",
    "\n",
    "**Steps**:\n",
    "1. Scale the rotated training data `X_train_rotated` using the `scaler` to create `X_train_rotated_sc`.\n",
    "2. Train the `MLPClassifier` on the scaled data `X_train_rotated_sc` and labels `y_train_augmented`.\n",
    "\n",
    "**Important for grading**:\n",
    "- Save your trained model as `model_rotated`.\n",
    "- Use `random_state=42` when instantiating the `MLPClassifier` for reproducibility.\n",
    "- Ensure your loss plot is displayed by making the plotting code the last expression in the cell or explicitly calling `plt.show()`.\n",
    "\n",
    "**Hint**: Refer to [Scikit-learn's MLPClassifier documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) for additional guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "X_train_rotated_sc = scaler.transform(X_train_rotated)\n",
    "X_test_secret_sc = scaler.transform(X_test_secret)\n",
    "\n",
    "if (load_saved_models or IS_GRADING_ENV) and os.path.exists('mlp_fashionmnist_rotated_model.joblib'):\n",
    "  model_rotated = joblib.load(\"mlp_fashionmnist_rotated_model.joblib\")\n",
    "else:\n",
    "  # TODO: initialize and train a new model on the rotated images\n",
    "  model_rotated = ...\n",
    "\n",
    "  if save_models:\n",
    "    joblib.dump(model_rotated, \"mlp_fashionmnist_rotated_model.joblib\")\n",
    "    print(\"Rotated model saved to disk.\")\n",
    "\n",
    "print(f\"Training accuracy (training on rotated images): {model_rotated.score(X_train_rotated_sc, y_train_augmented):.3f}\")\n",
    "print(f\"Test accuracy (original): {model.score(X_test_sc, y_test):.3f}\")\n",
    "print(f\"Test accuracy (training on rotated images): {model_rotated.score(X_test_secret_sc, y_test_secret):.3f}\")\n",
    "\n",
    "loss_df = pd.DataFrame({\n",
    "    'epoch': range(1, len(model_rotated.loss_curve_) + 1),\n",
    "    'loss': model_rotated.loss_curve_\n",
    "})\n",
    "loss_df.plot(x='epoch', y='loss', title=\"Training Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Problem 8: Solution 2 -- Undo the Rotations in the Secret Test Set\n",
    "\n",
    "In this approach, we aim to align the test distribution with the training distribution by building a regression model to predict the rotation angle of an image. Once the rotation angle is predicted, we can rotate the image back to its original orientation (angle 0) before feeding it into the classifier.\n",
    "\n",
    "### Problem 8a: Predicting Rotation Angles\n",
    "\n",
    "**Task**:\n",
    "Train a multi-layer perceptron (MLPRegressor) to predict the rotation angle of an image. Make sure you follow the same data processing steps from previous sections. We have provided the model and hyperparameters for you. \n",
    "\n",
    "**Instructions**:\n",
    "- Save your trained MLPRegressor as `model_rotation_regressor`.\n",
    "- Use `random_state=42` when instantiating your MLPRegressor to ensure reproducibility.\n",
    "- If your loss plot does not display, ensure the code for plotting the loss is the *last expression* in your Jupyter cell, or explicitly call `plt.show()`.\n",
    "\n",
    "**Hints**:\n",
    "1. Refer to [Scikit-learn's MLPRegressor documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) for guidance on configuring the model.\n",
    "2. Train the model for enough iterations to observe convergence. The `early_stopping` parameter can be helpful to stop training automatically once convergence is reached. If the model trains for too many iterations without converging, consider adjusting other MLPRegressor parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "if (load_saved_models or IS_GRADING_ENV) and os.path.exists('model_rotation_regression.joblib'):\n",
    "  model_rotation_regression = joblib.load(\"model_rotation_regression.joblib\")\n",
    "else:\n",
    "  # Train a larger regression model (MLP) to predict rotation angles\n",
    "  model_rotation_regression = MLPRegressor(\n",
    "      hidden_layer_sizes=(256, 128),\n",
    "      activation='relu',\n",
    "      solver='adam',\n",
    "      max_iter=100,\n",
    "      random_state=SEED,\n",
    "      early_stopping=True,\n",
    "      verbose=True\n",
    "  )\n",
    "  # TODO: train a MLP regressor to predict rotation angles\n",
    "  model_rotation_regression = ...\n",
    "  # Save model_rotation_regression and scaler\n",
    "  if save_models:\n",
    "    joblib.dump(model_rotation_regression, \"model_rotation_regression.joblib\")\n",
    "    joblib.dump(scaler, \"scaler.joblib\")\n",
    "    print(\"Rotation regression model and scaler saved to disk.\")\n",
    "\n",
    "loss_df = pd.DataFrame({\n",
    "    'epoch': range(1, len(model_rotation_regression.loss_curve_) + 1),\n",
    "    'loss': model_rotation_regression.loss_curve_\n",
    "})\n",
    "loss_df.plot(x='epoch', y='loss', title=\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Problem 8b: Evaluating the Rotation Angle Prediction Model\n",
    "\n",
    "In this task, we will evaluate the performance of our `model_rotation_regression` in predicting the rotation angles of images.\n",
    "\n",
    "**Steps**:\n",
    "1. Use the trained `model_rotation_regression` to predict the rotation angles for the images in `X_test_rotated_sc`.\n",
    "2. Calculate the **Mean Squared Error (MSE)** and **Root Mean Squared Error (RMSE)** of the predictions.\n",
    "\n",
    "**Hints**:\n",
    "- Use the [`mean_squared_error` function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) from `sklearn.metrics` to compute the MSE.\n",
    "- To calculate the RMSE, take the square root of the MSE. You can use `np.sqrt()` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Use the model_rotation_regression to predict the rotation angles on X_test_rotated_sc\n",
    "X_test_rotated, y_test_rotations = ...\n",
    "X_test_rotated_sc = ...\n",
    "\n",
    "y_pred_angles = ...\n",
    "mse = ...\n",
    "rmse = ...\n",
    "print(f\"Test MSE: {mse:.2f}\")\n",
    "print(f\"Test RMSE: {rmse:.2f} degrees\")\n",
    "\n",
    "# Show some predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"True rotation: {y_test_rotations[i]:.1f}°, Predicted: {y_pred_angles[i]:.1f}°\")\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"------------------------------\")\n",
    "print(f\"Test MSE (angle):  {mse:.2f}\")\n",
    "print(f\"Test RMSE:        {rmse:.2f}°\")\n",
    "print(\"------------------------------\")\n",
    "print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between the Predicted vs True Rotation Angle\n",
    "\n",
    "Let's visualize how well `model_rotation_regression` was able to predict the true rotation angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of predictions vs actual\n",
    "scatter_fig = go.Figure()\n",
    "scatter_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_test_rotations[:200],  # First 200 samples for clarity\n",
    "        y=y_pred_angles[:200],\n",
    "        mode='markers',\n",
    "        name='Predictions',\n",
    "        marker=dict(size=6, opacity=0.7)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add perfect prediction line\n",
    "max_angle = max(y_test_rotations[:200])\n",
    "scatter_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, max_angle],\n",
    "        y=[0, max_angle],\n",
    "        mode='lines',\n",
    "        name='Perfect Prediction',\n",
    "        line=dict(dash='dash', color='red')\n",
    "    )\n",
    ")\n",
    "\n",
    "scatter_fig.update_layout(\n",
    "    title='Predicted vs Actual Rotation Angles',\n",
    "    xaxis_title='Actual Angle (degrees)',\n",
    "    yaxis_title='Predicted Angle (degrees)',\n",
    "    width=600,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "scatter_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `model_rotation_regression` in Action \n",
    "Next, let's actually try to use the rotation angles that `model_rotation_regression` predicts to unrotate the images back to their original state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate unrotation using predicted angles\n",
    "def unrotate_image(rotated_image, predicted_angle):\n",
    "    \"\"\"\n",
    "    Unrotate an image by rotating it by the negative of the predicted angle.\n",
    "    \"\"\"\n",
    "    return rotate_image_by_angle(rotated_image, -predicted_angle)\n",
    "\n",
    "# Test unrotation on a sample\n",
    "sample_idx = 0\n",
    "original_test_image = X_test[sample_idx // 1]  # Get original unrotated image\n",
    "rotated_test_image = X_test_rotated[sample_idx] # Get the rotated image\n",
    "true_angle = y_test_rotations[sample_idx] # Get the true angle the image was rotated by\n",
    "predicted_angle = y_pred_angles[sample_idx] # Get the model's prediction\n",
    "unrotated_image = unrotate_image(rotated_test_image, predicted_angle)\n",
    "\n",
    "# Prepare images and titles for display\n",
    "images = [\n",
    "    original_test_image.reshape(28, 28)[::-1],\n",
    "    rotated_test_image.reshape(28, 28)[::-1],\n",
    "    unrotated_image.reshape(28, 28)[::-1]\n",
    "]\n",
    "titles = [\n",
    "    'Original',\n",
    "    f'Rotated by {true_angle:.1f}°',\n",
    "    f'After unrotating the image with the model\\'s prediction (pred: {predicted_angle:.1f}°)'\n",
    "]\n",
    "\n",
    "# Create a subplot grid using plotly express imshow\n",
    "fig = px.imshow(\n",
    "    np.stack(images),\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=3,\n",
    "    color_continuous_scale='gray',\n",
    "    aspect='auto'\n",
    ")\n",
    "\n",
    "# Update facet titles\n",
    "for i, title in enumerate(titles):\n",
    "    fig.layout.annotations[i]['text'] = title\n",
    "\n",
    "fig.update_layout(\n",
    "    height=300,\n",
    "    width=1200,\n",
    "    title_text=\"Image Rotation Prediction and Correction\",\n",
    "    coloraxis_showscale=False\n",
    ")\n",
    "fig.update_xaxes(showticklabels=False, showgrid=False, zeroline=False)\n",
    "fig.update_yaxes(showticklabels=False, showgrid=False, zeroline=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8c: Unrotating Images and Evaluating the Classifier\n",
    "\n",
    "**Task:**\n",
    "1. Unrotate the images in `X_test_secret` by predicting their rotation angles.\n",
    "\n",
    "    a. Scale the secret test set `X_test_secret` using the `scaler` and save the scaled data into the variable `X_test_secret_scaled`.\n",
    "\n",
    "    b. Use the trained `model_rotation_regression` to predict the rotation angles of the images (`y_pred_angles`).\n",
    "\n",
    "    c. Use the predicted rotation angles to *unrotate* the images in `X_test_secret`. Save the unrotated images into `X_test_unrotated`.\n",
    "\n",
    "    d. Scale the unrotated images using the `scaler` and save the scaled data into `X_test_unrotated_sc`.\n",
    "\n",
    "2. Evaluate the classifier on the unrotated images.\n",
    "\n",
    "    a. Use the original `MLPClassifier` (`model`) to make predictions on `X_test_unrotated_sc`.\n",
    "\n",
    "    b. Check which images are correctly classified.\n",
    "\n",
    "**Expected Output**:\n",
    "- Add two new columns to `test_secret_df`:\n",
    "  - `\"unrotated_predictions\"`: Contains the predicted classes for the unrotated images.\n",
    "  - `\"unrotated_correct\"`: Boolean values indicating whether the predicted class matches the ground truth.\n",
    "\n",
    "**Hints:**\n",
    "- Use [scaler.transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform) to scale the data before using `model_rotation_regression` to predict rotation angles and after unrotating the images.\n",
    "- Ensure that the unrotated images are properly scaled before passing them to `model` for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Scale the secret test set and use model_rotation_regression to unrotate the images in the secret test set\n",
    "X_test_secret_scaled = ...\n",
    "y_pred_angles = ...\n",
    "X_test_unrotated  = ...\n",
    "X_test_unrotated_sc = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8ci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Make new predictions using the original MLPClassifier model and check which images are correctly classified\n",
    "test_secret_df[\"unrotated_prediction\"] = ...\n",
    "test_secret_df[\"unrotated_correct\"] = test_secret_df[\"unrotated_prediction\"] = ...\n",
    "\n",
    "print(f\"Test accuracy: {test_secret_df.correct.mean():.3f}\")\n",
    "print(f\"Unrotated Test accuracy: {test_secret_df.unrotated_correct.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8cii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 8d: Comparing Data Augmentation and Rotation Correction\n",
    "\n",
    "**Question:** Why might the rotation correction approach (Solution 2) perform worse than the data augmentation approach (Solution 1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Let's compare our three strategies for handling rotated images: doing nothing (baseline), training a model on rotated data, and a two-step pipeline that predicts orientation then un-rotates before classification.\n",
    "\n",
    "1. First, we'll make predictions using our 3 strategies.\n",
    "2. Then, we'll store the accuracies of all 3 methods into a dataframe\n",
    "3. Lastly, we'll plot the accuracies in a color-coded bar chart and print the accuracies.\n",
    "\n",
    "Take a look at which method best overcomes the rotation effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three approaches\n",
    "baseline_accuracy = model.score(X_test_secret_sc, y_test_secret) # method: baseline\n",
    "rotated_training_accuracy = model_rotated.score(X_test_secret_sc, y_test_secret) # method: train on rotated images\n",
    "unrotated_accuracy = model.score(X_test_unrotated_sc, y_test_secret) # method: predict & unrotate, then classify the images we tried to unrotate\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': ['Baseline (no handling)', 'Train on rotated images', 'Predict & unrotate'],\n",
    "    'Accuracy': [baseline_accuracy, rotated_training_accuracy, unrotated_accuracy]\n",
    "})\n",
    "\n",
    "# Plot comparison\n",
    "fig = px.bar(\n",
    "    comparison_df,\n",
    "    x='Method',\n",
    "    y='Accuracy',\n",
    "    title='Comparison of Rotation Handling Methods',\n",
    "    color='Accuracy',\n",
    "    color_continuous_scale='RdYlGn'\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Method\",\n",
    "    yaxis_title=\"Test Accuracy\",\n",
    "    yaxis=dict(range=[0, 1])\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n=== Summary of All Methods ===\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    print(f\"{row['Method']}: {row['Accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9: Solution 3 -- Enhancing Accuracy with Test Time Augmentations\n",
    "\n",
    "Test Time Augmentation (TTA) is a powerful technique to improve model performance during inference by applying data transformations to the test data. For example, transformations such as rotations, flips, or other augmentations can be applied to the test images before passing them to the model. The predictions from these augmented images can then be aggregated to make a more robust final prediction.\n",
    "\n",
    "**Task:**\n",
    "1. Use test time augmentations to improve the accuracy of the original classifier. Your final accuracy must reach at least **58\\%**. Modify the `test_time_augmentation` function (and add any additional helper functions or transformations) as needed.\n",
    "\n",
    "    a. You are allowed to use the rotation prediction model (`model_rotation_regression`) and can make multiple inference calls per image.\n",
    "\n",
    "    b. You may reuse functions defined earlier in the notebook to implement your test-time augmentations.\n",
    "\n",
    "**Important for grading**:\n",
    "- You must use the original `MLPClassifier` (`model`) for classification and cannot train any additional models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "otter": {
     "tests": [
      "q9"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Write a function (or functions!) that can be used to improve the accuracy of the original MLPClassifer model using test time augmentations\n",
    "# Feel free to add additional functions, arguments, etc. as needed!\n",
    "def test_time_augmentation(model, scaler, image):\n",
    "    \"\"\"\n",
    "    Predict a label using test-time augmentation\n",
    "    Params:\n",
    "        - model: the MLPClassifier model\n",
    "        - scaler: the StandardScaler used to scale the images\n",
    "        - image: the image to be augmented\n",
    "    Returns:\n",
    "        - prediction: the predicted label\n",
    "    \"\"\"\n",
    "    ...\n",
    "    raise NotImplementedError(\"Not implemented\")\n",
    "\n",
    "\n",
    "# Make a copy of the test secret dataframe and apply the test time augmentation to the images to get new predictions!\n",
    "part_2_df = test_secret_df.copy()\n",
    "part_2_df[\"image\"] = part_2_df[\"image\"].apply(lambda x: np.array(x).reshape(-1))\n",
    "part_2_df[\"prediction\"] = part_2_df[\"image\"].apply(lambda x: test_time_augmentation(model, scaler, x))\n",
    "\n",
    "# Check the accuracy of the new predictions\n",
    "correct = part_2_df[\"prediction\"] == part_2_df[\"label\"]\n",
    "print(\"Accuracy:\", correct.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Before you submit, ensure `save_models` is true!\n",
    "\n",
    "**Important for grading**: Make sure you set these variables to True at the top of your notebook before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert save_models and load_saved_models, \"save_models and load_saved_models must be True\"\n",
    "\n",
    "assert os.path.exists('mlp_fashionmnist_model.joblib'), \"mlp_fashionmnist_model.joblib should exist\"\n",
    "assert os.path.exists('price_model.joblib'), \"price_model.joblib should exist\"\n",
    "assert os.path.exists('mlp_fashionmnist_rotated_model.joblib'), \"mlp_fashionmnist_rotated_model.joblib should exist\"\n",
    "assert os.path.exists('model_rotation_regression.joblib'), \"model_rotation_regression.joblib should exist\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this cell if you are running the notebook in Google Colab to install the necessary dependencies, this may take a few minutes\n",
    "if IS_COLAB:\n",
    "    !apt-get install -y texlive texlive-xetex pandoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True, files=['mlp_fashionmnist_model.joblib', 'price_model.joblib', 'mlp_fashionmnist_rotated_model.joblib', 'model_rotation_regression.joblib'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs189-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "require_no_pdf_confirmation": true,
   "tests": {
    "q5a": {
     "name": "q5a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(prices_test) == len(test_df), 'prices_test and test_df have different lengths'\n>>> assert 'price_prediction' in prices_test.columns, 'price_prediction column not found in prices_test'\n>>> assert isinstance(price_model, LinearRegression), 'price_model is not a LinearRegression model'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5b": {
     "name": "q5b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_compute_rmse():\n...     y_true = np.array([1, 2, 3, 10, 12])\n...     y_pred = np.array([1, 2, 3, 10, 12])\n...     expected_rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n...     assert np.isclose(compute_rmse(y_true, y_pred), expected_rmse), 'RMSE should be 0 for perfect prediction'\n...     y_pred = np.array([2, 2, 2, 4, 6])\n...     expected_rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n...     assert np.isclose(compute_rmse(y_true, y_pred), expected_rmse), 'RMSE calculation incorrect'\n>>> def test_compute_mae():\n...     y_true = np.array([1, 2, 3, 10, 12])\n...     y_pred = np.array([1, 2, 3, 10, 12])\n...     expected_mae = np.mean(np.abs(y_true - y_pred))\n...     assert np.isclose(compute_mae(y_true, y_pred), expected_mae), 'MAE should be 0 for perfect prediction'\n...     y_pred = np.array([2, 2, 2, 4, 6])\n...     expected_mae = np.mean(np.abs(y_true - y_pred))\n...     assert np.isclose(compute_mae(y_true, y_pred), expected_mae), 'MAE calculation incorrect'\n>>> def test_compute_r2():\n...     y_true = np.array([1, 2, 3, 10, 12])\n...     y_pred = np.array([1, 2, 3, 10, 12])\n...     ss_res = np.sum((y_true - y_pred) ** 2)\n...     ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n...     expected_r2 = 1 - ss_res / ss_tot\n...     assert np.isclose(compute_r2(y_true, y_pred), expected_r2), 'R2 should be 1 for perfect prediction'\n...     y_pred = np.array([2, 2, 2, 4, 6])\n...     ss_res = np.sum((y_true - y_pred) ** 2)\n...     ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n...     expected_r2 = 1 - ss_res / ss_tot\n...     assert np.isclose(compute_r2(y_true, y_pred), expected_r2), 'R2 calculation incorrect'\n>>> test_compute_rmse()\n>>> test_compute_mae()\n>>> test_compute_r2()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5d": {
     "name": "q5d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'misclassified_price_error' in locals(), 'misclassified_price_error is not defined'\n>>> assert 'correctly_classified_price_error' in locals(), 'correctly_classified_price_error is not defined'\n>>> assert isinstance(misclassified_price_error, float), 'misclassified_price_error is not a float'\n>>> assert isinstance(correctly_classified_price_error, float), 'correctly_classified_price_error is not a float'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6a": {
     "name": "q6a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(test_secret_df, pd.DataFrame)\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> assert len(test_secret_df) == 2000\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> assert 'correct' in test_secret_df.columns\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6c": {
     "name": "q6c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(conf_matrix, np.ndarray)\n>>> assert conf_matrix.shape == (len(model.classes_), len(model.classes_))\n>>> assert conf_matrix.sum() == len(y_test_secret)\n>>> assert np.issubdtype(conf_matrix.dtype, np.integer)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7a": {
     "name": "q7a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(X_train_rotated, np.ndarray)\n>>> assert isinstance(y_train_augmented, np.ndarray)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> assert X_train_rotated.shape[1] == 784\n>>> assert X_train_rotated.shape[0] == len(X_train) * num_rotations_per_image\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7b": {
     "name": "q7b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(model_rotated, MLPClassifier)\n>>> assert hasattr(model_rotated, 'coefs_') and len(model_rotated.coefs_) > 0\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> assert 'loss_df' in globals()\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8a": {
     "name": "q8a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(model_rotation_regression, MLPRegressor)\n>>> assert hasattr(model_rotation_regression, 'coefs_') and len(model_rotation_regression.coefs_) > 0\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> assert 'loss_df' in globals()\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8b": {
     "name": "q8b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(y_pred_angles) == len(X_test_rotated_sc)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> assert isinstance(mse, float)\n>>> assert isinstance(rmse, float)\n>>> assert mse >= 0\n>>> assert rmse >= 0\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8ci": {
     "name": "q8ci",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_test_secret_scaled.shape == X_test_secret.shape\n>>> assert hasattr(scaler, 'mean_') and hasattr(scaler, 'scale_')\n>>> assert np.isfinite(X_test_secret_scaled).all()\n>>> _expected = (X_test_secret - scaler.mean_) / scaler.scale_\n>>> np.testing.assert_allclose(X_test_secret_scaled, _expected, rtol=1e-06, atol=1e-06)\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> assert isinstance(y_pred_angles, np.ndarray)\n>>> assert y_pred_angles.dtype == np.float64\n>>> assert y_pred_angles.shape == (len(X_test_secret),)\n>>> assert (y_pred_angles >= -360).all() and (y_pred_angles <= 360).all()\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8cii": {
     "name": "q8cii",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> for col in ['unrotated_prediction', 'unrotated_correct']:\n...     assert col in test_secret_df.columns\n>>> assert test_secret_df['unrotated_correct'].dtype == bool\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
